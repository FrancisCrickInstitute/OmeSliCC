{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"OmeSliCC: Ome(ro) Slide Image Conversion and Compression pipeline","text":""},{"location":"overview/","title":"Overview","text":""},{"location":"overview/#omeslicc-omero-slide-image-conversion-and-compression-pipeline","title":"OmeSliCC: Ome(ro) Slide Image Conversion and Compression pipeline","text":"<p>OmeSliCC is designed to convert slides from common formats, to optimal OME formats for deep learning.</p> <p>This includes converting from Omero and extracting metadata as label information.</p> <p>For support and discussion, please use the Image.sc forum and post to the forum with the tag 'OmeSliCC'.</p>"},{"location":"overview/#main-features","title":"Main features","text":"<ul> <li>Import WSI files: Omero, Ome.Tiff, Tiff, Zarr, Ome.Zarr/NGFF, common slide formats, common image formats</li> <li>Export images: Tiff, Ome.Tiff, Zarr, Ome.Zarr, common image formats, thumbnails</li> <li>Integrated Dask support</li> <li>Zarr image compression (lossless/lossy)</li> <li>Image scaling using target pixel size</li> <li>Omero credentials helper</li> </ul> <p>For more info on OME/NGFF see OME NGFF</p>"},{"location":"overview/#running-omeslicc","title":"Running OmeSliCC","text":"<p>OmeSliCC is 100% Python and can be run as follows: - On a local environment using requirements.txt - With conda environment using the conda yaml file - As Docker container</p>"},{"location":"overview/#quickstart","title":"Quickstart","text":"<p>To start the conversion pipeline:</p> <pre><code>python run.py --params path/to/params.yml\n</code></pre> <p>See here for an example parameter file. The main sections are: - input: providing either a file/folder path, or Omero URL - output: specifying the location and desired format of the output - actions: which actions to perform:     - info: show input file information     - thumbnail: extract image thumbnail     - convert: convert to desired image output     - combine: combine separate channel images into multi-channel image(s)</p> <p>To encode credentials for Omero access:</p> <pre><code>python encode_omero_credentials.py --params path/to/params.yml\n</code></pre> <p>To extract Omero label metadata to text file:</p> <pre><code>python extract_omero_labels.py --params path/to/params.yml\n</code></pre>"},{"location":"references/","title":"References","text":""},{"location":"references/#OmeSliCC.BioSource","title":"<code>BioSource</code>","text":""},{"location":"references/#OmeSliCC.BioSource.BioSource","title":"<code>BioSource</code>","text":"<p>               Bases: <code>OmeSource</code></p> <p>bioformats compatible image source</p> Source code in <code>OmeSliCC\\BioSource.py</code> <pre><code>class BioSource(OmeSource):\n    \"\"\"bioformats compatible image source\"\"\"\n\n    filename: str\n    \"\"\"original filename\"\"\"\n    indexes: list\n    \"\"\"list of relevant series indexes\"\"\"\n\n    def __init__(self,\n                 filename: str,\n                 source_pixel_size: list = None,\n                 target_pixel_size: list = None,\n                 source_info_required: bool = False):\n\n        super().__init__()\n\n        open_javabridge()\n\n        xml_metadata = bioformats.get_omexml_metadata(filename)\n        self.bio_ome_metadata = bioformats.OMEXML(xml_metadata)\n        self.metadata = XmlDict.xml2dict(xml_metadata)\n        if 'OME' in self.metadata:\n            self.metadata = self.metadata['OME']\n            self.has_ome_metadata = True\n        self.reader = ImageReader(filename)\n\n        #self.reader.rdr.getSeriesCount()\n        # good images have StageLabel in metadata?\n        self.indexes = []\n        # TODO: use self.metadata instead of self.bio_ome_metadata\n        for i in range(self.bio_ome_metadata.get_image_count()):\n            pmetadata = self.bio_ome_metadata.image(i).Pixels\n            if pmetadata.PhysicalSizeX is not None:\n                dtype = np.dtype(pmetadata.PixelType)\n                self.indexes.append(i)\n                self.sizes.append((pmetadata.SizeX, pmetadata.SizeY))\n                self.sizes_xyzct.append((pmetadata.SizeX, pmetadata.SizeY, pmetadata.SizeZ, pmetadata.SizeC, pmetadata.SizeT))\n                self.pixel_types.append(dtype)\n                self.pixel_nbits.append(dtype.itemsize * 8)\n\n        self._init_metadata(filename,\n                            source_pixel_size=source_pixel_size,\n                            target_pixel_size=target_pixel_size,\n                            source_info_required=source_info_required)\n\n        self.is_rgb = self.get_nchannels() in (3, 4)\n\n        self.dimension_order = 'yx'\n        if self.get_nchannels() &gt; 1:\n            self.dimension_order += 'c'\n\n    def _find_metadata(self):\n        self._get_ome_metadata()\n\n    def _asarray_level(self, level: int, **slicing) -&gt; np.ndarray:\n        x0, x1 = slicing.get('x0', 0), slicing.get('x1', -1)\n        y0, y1 = slicing.get('y0', 0), slicing.get('y1', -1)\n        c, t, z = slicing.get('c'), slicing.get('t'), slicing.get('z')\n        if x1 &lt; 0 or y1 &lt; 0:\n            x1, y1 = self.sizes[level]\n        if t is None:\n            t = 0\n        if z is None:\n            z = 0\n        xywh = (x0, y0, x1 - x0, y1 - y0)\n        # don't 'rescale' to 0-1!\n        image = self.reader.read(series=self.indexes[level], XYWH=xywh, c=c, z=z, t=t, rescale=False)\n        out = redimension_data(image, self.dimension_order, self.get_dimension_order())\n        return out\n\n    def close(self):\n        self.reader.close()\n</code></pre>"},{"location":"references/#OmeSliCC.BioSource.BioSource.filename","title":"<code>filename</code>  <code>instance-attribute</code>","text":"<p>original filename</p>"},{"location":"references/#OmeSliCC.BioSource.BioSource.indexes","title":"<code>indexes = []</code>  <code>instance-attribute</code>","text":"<p>list of relevant series indexes</p>"},{"location":"references/#OmeSliCC.OmeSource","title":"<code>OmeSource</code>","text":""},{"location":"references/#OmeSliCC.OmeSource.OmeSource","title":"<code>OmeSource</code>","text":"<p>OME-compatible image source (base class)</p> Source code in <code>OmeSliCC\\OmeSource.py</code> <pre><code>class OmeSource:\n    \"\"\"OME-compatible image source (base class)\"\"\"\n    \"\"\"Internal image format is [TCZYX]\"\"\"\n\n    metadata: dict\n    \"\"\"metadata dictionary\"\"\"\n    has_ome_metadata: bool\n    \"\"\"has ome metadata\"\"\"\n    dimension_order: str\n    \"\"\"source dimension order\"\"\"\n    output_dimension_order: str\n    \"\"\"data dimension order\"\"\"\n    source_pixel_size: list\n    \"\"\"original source pixel size\"\"\"\n    target_pixel_size: list\n    \"\"\"target pixel size\"\"\"\n    sizes: list\n    \"\"\"x/y size pairs for all pages\"\"\"\n    sizes_xyzct: list\n    \"\"\"xyzct size for all pages\"\"\"\n    pixel_types: list\n    \"\"\"pixel types for all pages\"\"\"\n    pixel_nbits: list\n    \"\"\"#bits for all pages\"\"\"\n    channels: list\n    \"\"\"channel information for all image channels\"\"\"\n    position: list\n    \"\"\"source position information\"\"\"\n    rotation: float\n    \"\"\"source rotation information\"\"\"\n\n    default_properties_order = 'xyzct'\n    default_physical_unit = '\u00b5m'\n\n    def __init__(self):\n        self.metadata = {}\n        self.has_ome_metadata = False\n        self.dimension_order = ''\n        self.output_dimension_order = ''\n        self.source_pixel_size = []\n        self.target_pixel_size = []\n        self.sizes = []\n        self.sizes_xyzct = []\n        self.pixel_types = []\n        self.pixel_nbits = []\n        self.channels = []\n\n    def _init_metadata(self,\n                       source_reference: str,\n                       source_pixel_size: list = None,\n                       target_pixel_size: list = None,\n                       source_info_required: bool = False):\n\n        self.source_reference = source_reference\n        self.target_pixel_size = target_pixel_size\n        self._find_metadata()\n        if (len(self.source_pixel_size) == 0 or self.source_pixel_size[0][0] == 0\n                or self.source_pixel_size[0][1] == '' or self.source_pixel_size[0][1] == 'inch') \\\n                and source_pixel_size is not None:\n            # if pixel size is not set, or default/unspecified value\n            self.source_pixel_size = source_pixel_size\n        if len(self.source_pixel_size) == 0 or self.source_pixel_size[0][0] == 0:\n            msg = f'{source_reference}: No source pixel size in metadata or provided'\n            if source_info_required:\n                raise ValueError(msg)\n            else:\n                logging.warning(msg)\n        self._init_sizes()\n\n    def _get_ome_metadata(self):\n        images = ensure_list(self.metadata.get('Image', {}))[0]\n        pixels = images.get('Pixels', {})\n        self.source_pixel_size = []\n        size = float(pixels.get('PhysicalSizeX', 0))\n        if size &gt; 0:\n            self.source_pixel_size.append((size, pixels.get('PhysicalSizeXUnit', self.default_physical_unit)))\n        size = float(pixels.get('PhysicalSizeY', 0))\n        if size &gt; 0:\n            self.source_pixel_size.append((size, pixels.get('PhysicalSizeYUnit', self.default_physical_unit)))\n        size = float(pixels.get('PhysicalSizeZ', 0))\n        if size &gt; 0:\n            self.source_pixel_size.append((size, pixels.get('PhysicalSizeZUnit', self.default_physical_unit)))\n\n        position = []\n        for plane in ensure_list(pixels.get('Plane', [])):\n            position = []\n            if 'PositionX' in plane:\n                position.append((float(plane.get('PositionX')), plane.get('PositionXUnit', self.default_physical_unit)))\n            if 'PositionY' in plane:\n                position.append((float(plane.get('PositionY')), plane.get('PositionYUnit', self.default_physical_unit)))\n            if 'PositionZ' in plane:\n                position.append((float(plane.get('PositionZ')), plane.get('PositionZUnit', self.default_physical_unit)))\n            #c, z, t = plane.get('TheC'), plane.get('TheZ'), plane.get('TheT')\n            break\n        self.position = position\n\n        rotation = None\n        annotations = self.metadata.get('StructuredAnnotations')\n        if annotations is not None:\n            if not isinstance(annotations, (list, tuple)):\n                annotations = [annotations]\n            for annotation_item in annotations:\n                for annotations2 in annotation_item.values():\n                    if not isinstance(annotations2, (list, tuple)):\n                        annotations2 = [annotations2]\n                    for annotation in annotations2:\n                        value = annotation.get('Value')\n                        unit = None\n                        if isinstance(value, dict) and 'Modulo' in value:\n                            modulo = value.get('Modulo', {}).get('ModuloAlongZ', {})\n                            unit = modulo.get('Unit')\n                            value = modulo.get('Label')\n                        elif isinstance(value, str) and value.lower().startswith('angle'):\n                            if ':' in value:\n                                value = value.split(':')[1].split()\n                            elif '=' in value:\n                                value = value.split('=')[1].split()\n                            else:\n                                value = value.split()[1:]\n                            if len(value) &gt;= 2:\n                                unit = value[1]\n                            value = value[0]\n                        else:\n                            value = None\n                        if value is not None:\n                            rotation = float(value)\n                            if 'rad' in unit.lower():\n                                rotation = np.rad2deg(rotation)\n        self.rotation = rotation\n\n        self.source_mag = 0\n        objective_id = images.get('ObjectiveSettings', {}).get('ID', '')\n        for objective in ensure_list(self.metadata.get('Instrument', {}).get('Objective', [])):\n            if objective.get('ID', '') == objective_id:\n                self.source_mag = float(objective.get('NominalMagnification', 0))\n        nchannels = self.get_nchannels()\n        channels = []\n        for channel0 in ensure_list(pixels.get('Channel', [])):\n            channel = {'label': channel0.get('Name', '')}\n            color = channel0.get('Color')\n            if color:\n                channel['color'] = int_to_rgba(int(color))\n            channels.append(channel)\n        if len(channels) == 0:\n            if nchannels == 3:\n                channels = [{'label': ''}]\n            else:\n                channels = [{'label': str(channeli)} for channeli in range(nchannels)]\n        self.channels = channels\n\n    def _init_sizes(self):\n        # normalise source pixel sizes\n        standard_units = {'nano': 'nm', 'micro': '\u00b5m', 'milli': 'mm', 'centi': 'cm'}\n        pixel_size = []\n        for pixel_size0 in self.source_pixel_size:\n            pixel_size1 = check_round_significants(pixel_size0[0], 6)\n            unit1 = pixel_size0[1]\n            for standard_unit in standard_units:\n                if unit1.lower().startswith(standard_unit):\n                    unit1 = standard_units[standard_unit]\n            pixel_size.append((pixel_size1, unit1))\n        if 0 &lt; len(pixel_size) &lt; 2:\n            pixel_size.append(pixel_size[0])\n        self.source_pixel_size = pixel_size\n\n        if self.target_pixel_size is None:\n            self.target_pixel_size = self.source_pixel_size\n\n        if 0 &lt; len(self.target_pixel_size) &lt; 2:\n            self.target_pixel_size.append(self.target_pixel_size[0])\n\n        # set source mags\n        self.source_mags = [self.source_mag]\n        for i, size in enumerate(self.sizes):\n            if i &gt; 0:\n                mag = self.source_mag * np.mean(np.divide(size, self.sizes[0]))\n                self.source_mags.append(check_round_significants(mag, 3))\n\n        if self.target_pixel_size:\n            self.best_level, self.best_factor, self.full_factor = get_best_level_factor(self, self.target_pixel_size)\n        else:\n            self.best_level = 0\n            self.best_factor = 1\n\n        if self.dimension_order == '':\n            x, y, z, c, t = self.get_size_xyzct()\n            if t &gt; 1:\n                self.dimension_order += 't'\n            if c &gt; 1:\n                self.dimension_order += 'c'\n            if z &gt; 1:\n                self.dimension_order += 'z'\n            self.dimension_order += 'yx'\n\n        self.output_dimension_order = 'tczyx'\n\n    def get_source_dask(self):\n        raise NotImplementedError('Implement method in subclass')\n\n    def get_mag(self) -&gt; float:\n        mag = self.source_mag\n        # get effective mag at target pixel size\n        if self.target_pixel_size:\n            mag *= np.mean(self.full_factor)\n        return check_round_significants(mag, 3)\n\n    def get_dimension_order(self) -&gt; str:\n        return self.output_dimension_order\n\n    def get_physical_size(self) -&gt; tuple:\n        physical_size = []\n        for size, pixel_size in zip(self.get_size_xyzct(), self.get_pixel_size()):\n            physical_size.append((np.multiply(size, pixel_size[0]), pixel_size[1]))\n        return tuple(physical_size)\n\n    def get_pixel_type(self, level: int = 0) -&gt; np.dtype:\n        return self.pixel_types[level]\n\n    def get_pixel_nbytes(self, level: int = 0) -&gt; int:\n        return self.pixel_nbits[level] // 8\n\n    def get_channels(self) -&gt; list:\n        return self.channels\n\n    def get_size(self) -&gt; tuple:\n        # size at target pixel size\n        return tuple(np.round(np.multiply(self.sizes[self.best_level], self.best_factor)).astype(int))\n\n    def get_size_xyzct(self) -&gt; tuple:\n        xyzct = list(self.sizes_xyzct[self.best_level]).copy()\n        size = self.get_size()\n        xyzct[0:2] = size\n        return tuple(xyzct)\n\n    def get_nchannels(self):\n        return self.sizes_xyzct[0][3]\n\n    def get_pixel_size(self) -&gt; list:\n        return self.target_pixel_size\n\n    def get_pixel_size_micrometer(self):\n        return get_value_units_micrometer(self.get_pixel_size())\n\n    def get_position(self) -&gt; list:\n        return self.position\n\n    def get_position_micrometer(self):\n        return get_value_units_micrometer(self.get_position())\n\n    def get_rotation(self) -&gt; float:\n        return self.rotation\n\n    def get_shape(self, dimension_order: str = None, xyzct: tuple = None) -&gt; tuple:\n        shape = []\n        if dimension_order is None:\n            dimension_order = self.get_dimension_order()\n        if xyzct is None:\n            xyzct = self.get_size_xyzct()\n        for dimension in dimension_order:\n            index = 'xyzct'.index(dimension)\n            shape.append(xyzct[index])\n        return tuple(shape)\n\n    def get_thumbnail(self, target_size: tuple, precise: bool = False) -&gt; np.ndarray:\n        size, index = get_best_size(self.sizes, target_size)\n        scale = np.divide(target_size, self.sizes[index])\n        new_dimension_order = 'yxc'\n        image = redimension_data(self._asarray_level(index), self.get_dimension_order(), new_dimension_order, t=0, z=0)\n        if precise:\n            thumbnail = precise_resize(image, scale)\n        else:\n            thumbnail = image_resize(image, target_size)\n        thumbnail_rgb = self.render(thumbnail, new_dimension_order)\n        return thumbnail_rgb\n\n    def get_channel_window(self, channeli):\n        min_quantile = 0.001\n        max_quantile = 0.999\n\n        if channeli &lt; len(self.channels) and 'window' in self.channels[channeli]:\n            return self.channels[channeli].get('window')\n\n        dtype = self.get_pixel_type()\n        if dtype.kind == 'f':\n            # info = np.finfo(dtype)\n            start, end = 0, 1\n        else:\n            info = np.iinfo(dtype)\n            start, end = info.min, info.max\n\n        nsizes = len(self.sizes)\n        if nsizes &gt; 1:\n            image = self._asarray_level(nsizes - 1)\n            image = np.asarray(image[:, channeli:channeli+1, ...])\n            min, max = get_image_quantile(image, min_quantile), get_image_quantile(image, max_quantile)\n        else:\n            # do not query full size image\n            min, max = start, end\n        return {'start': start, 'end': end, 'min': min, 'max': max}\n\n    def render(self, image: np.ndarray, source_dimension_order: str = None, t: int = 0, z: int = 0, channels: list = []) -&gt; np.ndarray:\n        if source_dimension_order is None:\n            source_dimension_order = self.get_dimension_order()\n        image = redimension_data(image, source_dimension_order, 'yxc', t=t, z=z)\n        total_image = None\n        n = len(self.channels)\n        is_rgb = (self.get_nchannels() in (3, 4) and (n &lt;= 1 or n == 3))\n        needs_normalisation = (image.dtype.itemsize == 2)\n\n        if not is_rgb:\n            tot_alpha = 0\n            for channeli, channel in enumerate(self.channels):\n                if not channels or channeli in channels:\n                    if n == 1:\n                        channel_values = image\n                    else:\n                        channel_values = image[..., channeli]\n                    if needs_normalisation:\n                        window = self.get_channel_window(channeli)\n                        channel_values = normalise_values(channel_values, window['min'], window['max'])\n                    else:\n                        channel_values = int2float_image(channel_values)\n                    new_channel_image = np.atleast_3d(channel_values)\n                    color = channel.get('color')\n                    if color:\n                        rgba = color\n                    else:\n                        rgba = [1, 1, 1, 1]\n                    color = rgba[:3]\n                    alpha = rgba[3]\n                    if alpha == 0:\n                        alpha = 1\n                    new_channel_image = new_channel_image * np.multiply(color, alpha).astype(np.float32)\n                    if total_image is None:\n                        total_image = new_channel_image\n                    else:\n                        total_image += new_channel_image\n                    tot_alpha += alpha\n            if tot_alpha != 1:\n                total_image /= tot_alpha\n            final_image = float2int_image(total_image,\n                                          target_dtype=image.dtype)\n        elif needs_normalisation:\n            window = self.get_channel_window(0)\n            final_image = float2int_image(normalise_values(image, window['min'], window['max']),\n                                          target_dtype=image.dtype)\n        else:\n            final_image = image\n        return final_image\n\n    def asarray(self, pixel_size: list = [], **slicing) -&gt; np.ndarray:\n        # expects x0, x1, y0, y1, ...\n        x0, x1 = slicing.get('x0', 0), slicing.get('x1', -1)\n        y0, y1 = slicing.get('y0', 0), slicing.get('y1', -1)\n        # allow custom pixel size\n        if pixel_size:\n            level, factor, _ = get_best_level_factor(self, pixel_size)\n            size0 = np.round(np.multiply(self.sizes[level], factor)).astype(int)\n        else:\n            level, factor = self.best_level, self.best_factor\n            size0 = self.get_size()\n\n        if x1 &lt; 0 or y1 &lt; 0:\n            x1, y1 = size0\n        if np.mean(factor) != 1:\n            slicing['x0'], slicing['y0'] = np.round(np.divide([x0, y0], factor)).astype(int)\n            slicing['x1'], slicing['y1'] = np.round(np.divide([x1, y1], factor)).astype(int)\n        image0 = self._asarray_level(level=level, **slicing)\n        if np.mean(factor) != 1:\n            size1 = x1 - x0, y1 - y0\n            image = image_resize(image0, size1, dimension_order=self.get_dimension_order())\n        else:\n            image = image0\n        return image\n\n    def asarray_um(self, **slicing):\n        pixel_size = self.get_pixel_size_micrometer()[:2]\n        slicing['x0'], slicing['y0'] = np.divide([slicing.get('x0'), slicing.get('y0')], pixel_size)\n        slicing['x1'], slicing['y1'] = np.divide([slicing.get('x1'), slicing.get('y1')], pixel_size)\n        return self.asarray(**slicing)\n\n    def asdask(self, chunk_size: tuple) -&gt; da.Array:\n        chunk_shape = list(np.flip(chunk_size))\n        while len(chunk_shape) &lt; 3:\n            chunk_shape = [1] + chunk_shape\n        chunk_shape = [self.get_nchannels()] + chunk_shape\n        while len(chunk_shape) &lt; 5:\n            chunk_shape = [1] + chunk_shape\n        chunks = np.ceil(np.flip(self.get_size_xyzct()) / chunk_shape).astype(int)\n        w, h = self.get_size()\n\n        delayed_reader = dask.delayed(self.asarray)\n        dtype = self.get_pixel_type()\n\n        dask_times = []\n        for ti in range(chunks[0]):\n            dask_planes = []\n            for zi in range(chunks[2]):\n                dask_rows = []\n                for yi in range(chunks[3]):\n                    dask_row = []\n                    for xi in range(chunks[4]):\n                        shape = list(chunk_shape).copy()\n                        x0, x1 = xi * shape[4], (xi + 1) * shape[4]\n                        y0, y1 = yi * shape[3], (yi + 1) * shape[3]\n                        if x1 &gt; w:\n                            x1 = w\n                            shape[4] = w - x0\n                        if y1 &gt; h:\n                            y1 = h\n                            shape[3] = h - y0\n                        z = zi * shape[2]\n                        t = ti * shape[0]\n                        dask_tile = da.from_delayed(delayed_reader(x0=x0, x1=x1, y0=y0, y1=y1, z=z, t=t),\n                                                    shape=shape, dtype=dtype)\n                        dask_row.append(dask_tile)\n                    dask_rows.append(da.concatenate(dask_row, axis=4))\n                dask_planes.append(da.concatenate(dask_rows, axis=3))\n            dask_times.append(da.concatenate(dask_planes, axis=2))\n        dask_data = da.concatenate(dask_times, axis=0)\n        return dask_data\n\n    def clone_empty(self) -&gt; np.ndarray:\n        return np.zeros(self.get_shape(), dtype=self.get_pixel_type())\n\n    def produce_chunks(self, chunk_size: tuple) -&gt; tuple:\n        w, h = self.get_size()\n        ny = int(np.ceil(h / chunk_size[1]))\n        nx = int(np.ceil(w / chunk_size[0]))\n        for chunky in range(ny):\n            for chunkx in range(nx):\n                x0, y0 = chunkx * chunk_size[0], chunky * chunk_size[1]\n                x1, y1 = min((chunkx + 1) * chunk_size[0], w), min((chunky + 1) * chunk_size[1], h)\n                indices = 0, 0, 0, y0, x0\n                yield indices, self.asarray(x0=x0, x1=x1, y0=y0, y1=y1)\n\n    def get_metadata(self) -&gt; dict:\n        return self.metadata\n\n    def create_xml_metadata(self, output_filename: str, combine_rgb: bool = True, pyramid_sizes_add: list = None) -&gt; str:\n        return create_ome_metadata(self, output_filename, combine_rgb=combine_rgb, pyramid_sizes_add=pyramid_sizes_add)\n\n    def _find_metadata(self):\n        raise NotImplementedError('Implement method in subclass')\n\n    def _asarray_level(self, level: int, **slicing) -&gt; np.ndarray:\n        raise NotImplementedError('Implement method in subclass')\n\n    def close(self):\n        pass\n</code></pre>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.channels","title":"<code>channels = []</code>  <code>instance-attribute</code>","text":"<p>channel information for all image channels</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.dimension_order","title":"<code>dimension_order = ''</code>  <code>instance-attribute</code>","text":"<p>source dimension order</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.has_ome_metadata","title":"<code>has_ome_metadata = False</code>  <code>instance-attribute</code>","text":"<p>has ome metadata</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.metadata","title":"<code>metadata = {}</code>  <code>instance-attribute</code>","text":"<p>metadata dictionary</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.output_dimension_order","title":"<code>output_dimension_order = ''</code>  <code>instance-attribute</code>","text":"<p>data dimension order</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.pixel_nbits","title":"<code>pixel_nbits = []</code>  <code>instance-attribute</code>","text":""},{"location":"references/#OmeSliCC.OmeSource.OmeSource.pixel_nbits--bits-for-all-pages","title":"bits for all pages","text":""},{"location":"references/#OmeSliCC.OmeSource.OmeSource.pixel_types","title":"<code>pixel_types = []</code>  <code>instance-attribute</code>","text":"<p>pixel types for all pages</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.position","title":"<code>position</code>  <code>instance-attribute</code>","text":"<p>source position information</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.rotation","title":"<code>rotation</code>  <code>instance-attribute</code>","text":"<p>source rotation information</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.sizes","title":"<code>sizes = []</code>  <code>instance-attribute</code>","text":"<p>x/y size pairs for all pages</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.sizes_xyzct","title":"<code>sizes_xyzct = []</code>  <code>instance-attribute</code>","text":"<p>xyzct size for all pages</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.source_pixel_size","title":"<code>source_pixel_size = []</code>  <code>instance-attribute</code>","text":"<p>original source pixel size</p>"},{"location":"references/#OmeSliCC.OmeSource.OmeSource.target_pixel_size","title":"<code>target_pixel_size = []</code>  <code>instance-attribute</code>","text":"<p>target pixel size</p>"},{"location":"references/#OmeSliCC.OmeZarrSource","title":"<code>OmeZarrSource</code>","text":""},{"location":"references/#OmeSliCC.OmeZarrSource.OmeZarrSource","title":"<code>OmeZarrSource</code>","text":"<p>               Bases: <code>OmeSource</code></p> <p>Zarr-compatible image source</p> Source code in <code>OmeSliCC\\OmeZarrSource.py</code> <pre><code>class OmeZarrSource(OmeSource):\n    \"\"\"Zarr-compatible image source\"\"\"\n\n    filename: str\n    \"\"\"original filename / URL\"\"\"\n    levels: list\n    \"\"\"list of all image arrays for different sizes\"\"\"\n    level_scales: list\n    \"\"\"list of all image (xy) scales\"\"\"\n    shapes: list\n    \"\"\"list of image shapes\"\"\"\n    chunk_shapes: list\n    \"\"\"list of image chunk shapes\"\"\"\n\n    def __init__(self, filename: str,\n                 source_pixel_size: list = None,\n                 target_pixel_size: list = None,\n                 source_info_required: bool = False):\n\n        super().__init__()\n\n        self.levels = []\n        self.level_scales = []\n        self.shapes = []\n        self.chunk_shapes = []\n        nchannels = 1\n        try:\n            location = parse_url(filename)\n            if location is None:\n                raise FileNotFoundError(f'Error parsing ome-zarr file {filename}')\n            reader = Reader(location)\n            # nodes may include images, labels etc\n            nodes = list(reader())\n            # first node will be the image pixel data\n            if len(nodes) == 0:\n                raise FileNotFoundError(f'No image data found in ome-zarr file {filename}')\n            image_node = nodes[0]\n\n            self.metadata = image_node.metadata\n            # channel metadata from ome-zarr-py limited; get from root_attrs manually\n            self.root_metadata = reader.zarr.root_attrs\n\n            axes = self.metadata.get('axes', [])\n            self.dimension_order = ''.join([axis.get('name') for axis in axes])\n\n            for data in image_node.data:\n                self.levels.append(data)\n\n                xyzct = [1, 1, 1, 1, 1]\n                for i, n in enumerate(data.shape):\n                    xyzct_index = self.default_properties_order.index(self.dimension_order[i])\n                    xyzct[xyzct_index] = n\n                self.sizes_xyzct.append(xyzct)\n                self.sizes.append((xyzct[0], xyzct[1]))\n                self.pixel_types.append(data.dtype)\n                self.pixel_nbits.append(data.dtype.itemsize * 8)\n                self.level_scales.append(np.divide(self.sizes_xyzct[0][0], xyzct[0]))\n                self.shapes.append(np.flip(reorder(data.shape, self.dimension_order, self.default_properties_order)))\n                self.chunk_shapes.append(np.flip(reorder(data.chunksize, self.dimension_order, self.default_properties_order)))\n                nchannels = xyzct[3]\n        except Exception as e:\n            raise FileNotFoundError(f'Read error: {e}')\n\n        self.is_rgb = nchannels in (3, 4)\n\n        self._init_metadata(filename,\n                            source_pixel_size=source_pixel_size,\n                            target_pixel_size=target_pixel_size,\n                            source_info_required=source_info_required)\n\n    def _find_metadata(self):\n        pixel_size = []\n        position = []\n        channels = []\n        metadata = self.metadata\n        axes = self.dimension_order\n\n        units = [axis.get('unit', '') for axis in metadata.get('axes', [])]\n\n        scale1 = [1] * len(metadata.get('axes'))\n        position1 = [0] * len(metadata.get('axes'))\n        # get pixelsize using largest/first scale\n        transform = self.metadata.get('coordinateTransformations', [])\n        if transform:\n            for transform1 in transform[0]:\n                if transform1['type'] == 'scale':\n                    scale1 = transform1['scale']\n                if transform1['type'] == 'translation':\n                    position1 = transform1['translation']\n            for axis in 'xyz':\n                if axis in axes:\n                    index = axes.index(axis)\n                    pixel_size.append((scale1[index], units[index]))\n                    position.append((position1[index], units[index]))\n                else:\n                    pixel_size.append((1, ''))\n                    position.append((0, ''))\n        nchannels = self.sizes_xyzct[0][3]\n        # look for channel metadata\n        for data in self.root_metadata.values():\n            if isinstance(data, dict) and 'channels' in data:\n                channels = data['channels'].copy()\n                for channel in channels:\n                    color = channel.pop('color', '')\n                    if color != '':\n                        if isinstance(color, int):\n                            color = int_to_rgba(color)\n                        else:\n                            color = hexrgb_to_rgba(color)\n                        channel['color'] = color\n        if len(channels) == 0:\n            if self.is_rgb:\n                channels = [{'label': ''}]\n            else:\n                channels = [{'label': ''}] * nchannels\n        self.source_pixel_size = pixel_size\n        self.channels = channels\n        self.source_mag = 0\n        self.position = position\n\n    def get_source_dask(self):\n        return self.levels\n\n    def _asarray_level(self, level: int, **slicing) -&gt; np.ndarray:\n        redim = redimension_data(self.levels[level], self.dimension_order, self.get_dimension_order())\n        slices = get_numpy_slicing(self.get_dimension_order(), **slicing)\n        out = redim[slices]\n        return out\n</code></pre>"},{"location":"references/#OmeSliCC.OmeZarrSource.OmeZarrSource.chunk_shapes","title":"<code>chunk_shapes = []</code>  <code>instance-attribute</code>","text":"<p>list of image chunk shapes</p>"},{"location":"references/#OmeSliCC.OmeZarrSource.OmeZarrSource.filename","title":"<code>filename</code>  <code>instance-attribute</code>","text":"<p>original filename / URL</p>"},{"location":"references/#OmeSliCC.OmeZarrSource.OmeZarrSource.level_scales","title":"<code>level_scales = []</code>  <code>instance-attribute</code>","text":"<p>list of all image (xy) scales</p>"},{"location":"references/#OmeSliCC.OmeZarrSource.OmeZarrSource.levels","title":"<code>levels = []</code>  <code>instance-attribute</code>","text":"<p>list of all image arrays for different sizes</p>"},{"location":"references/#OmeSliCC.OmeZarrSource.OmeZarrSource.shapes","title":"<code>shapes = []</code>  <code>instance-attribute</code>","text":"<p>list of image shapes</p>"},{"location":"references/#OmeSliCC.Omero","title":"<code>Omero</code>","text":""},{"location":"references/#OmeSliCC.Omero.Omero","title":"<code>Omero</code>","text":"<p>Omero image and metadata extraction</p> Source code in <code>OmeSliCC\\Omero.py</code> <pre><code>class Omero:\n    \"\"\"Omero image and metadata extraction\"\"\"\n\n    def __init__(self, params: dict):\n        self.params = params\n        self.private_key_filename = params['credentials']['private_key']\n        self.credentials_filename = params['credentials']['credentials']\n        self.connected = False\n\n    def __enter__(self) -&gt; Omero:\n        self.init()\n        return self\n\n    def __exit__(self, exc_type: type[BaseException], exc_value: BaseException, traceback: TracebackType):\n        self.close()\n\n    def init(self):\n        self._connect()\n        self._switch_user_group()\n\n    def close(self):\n        self._disconnect()\n\n    def _connect(self):\n        logging.info('Connecting to Omero...')\n        usr, pwd = decrypt_credentials(self.private_key_filename, self.credentials_filename)\n        self.conn = BlitzGateway(usr, pwd, host=self.params['input']['omero']['host'], secure=True)\n        if not self.conn.connect():\n            self._disconnect()\n            logging.error('Omero connection error')\n            raise ConnectionError\n        self.conn.c.enableKeepAlive(60)\n        self.connected = True\n        logging.info(f'Connected as {self.conn.getUser().getName()}')\n\n    def _disconnect(self):\n        self.conn.close()\n        self.connected = False\n\n    def _switch_user_group(self):\n        self.conn.SERVICE_OPTS.setOmeroGroup('-1')\n\n    def _get_project(self, project_id: int) -&gt; omero.gateway.ProjectWrapper:\n        project = self.conn.getObject('Project', project_id)\n        return project\n\n    def _get_dataset(self, dataset_id: int) -&gt; omero.gateway.DatasetWrapper:\n        dataset = self.conn.getObject('Dataset', dataset_id)\n        return dataset\n\n    def get_image_object(self, image_id: int) -&gt; omero.gateway.ImageWrapper:\n        image_object = self.conn.getObject('Image', image_id)\n        return image_object\n\n    def create_pixels_store(self, image_object: omero.gateway.ImageWrapper) -&gt; omero.gateway.ProxyObjectWrapper:\n        pixels_store = self.conn.createRawPixelsStore()\n        pixels_store.setPixelsId(image_object.getPixelsId(), False, self.conn.SERVICE_OPTS)\n        return pixels_store\n\n    def get_annotation_image_ids(self) -&gt; dict:\n        images_final = {}\n        input_omero = self.params['input'].get('omero', {})\n        include_params = input_omero['include']\n        include_regex = ensure_list(include_params.get('regex', []))\n        exclude_params = input_omero.get('exclude', {})\n        exclude_regex = ensure_list(exclude_params.get('regex', []))\n        # include\n        image_ids = set(ensure_list(include_params.get('image', [])))\n        images = {image_id: self.get_image_object(image_id) for image_id in image_ids}\n        for dataset_id in ensure_list(include_params.get('dataset', [])):\n            images.update(self._get_dataset_images(dataset_id))\n        for project_id in ensure_list(include_params.get('project', [])):\n            project = self._get_project(project_id)\n            for dataset in project.listChildren():\n                images.update(self._get_dataset_images(dataset.getId()))\n        # exclude\n        for image_id in ensure_list(exclude_params.get('image', [])):\n            images.pop(image_id, None)\n        for dataset_id in ensure_list(exclude_params.get('dataset', [])):\n            for image_id in self._get_dataset_images(dataset_id):\n                images.pop(image_id, None)\n        for project_id in ensure_list(exclude_params.get('project', [])):\n            project = self._get_project(project_id)\n            for dataset in project.listChildren():\n                for image_id in self._get_dataset_images(dataset.getId()):\n                    images.pop(image_id, None)\n\n        # regex\n        for image_id, image in images.items():\n            name = image.getName()\n            include = True\n            if include_regex:\n                include = False\n                for pattern in include_regex:\n                    if re.search(pattern, name, re.IGNORECASE):\n                        include = True\n            if exclude_regex:\n                for pattern in exclude_regex:\n                    if re.search(pattern, name, re.IGNORECASE):\n                        include = False\n            if include:\n                images_final[image_id] = image\n        return images_final\n\n    def _get_dataset_images(self, dataset_id: int) -&gt; dict:\n        dataset = self._get_dataset(dataset_id)\n        return {image.getId(): image for image in dataset.listChildren()}\n\n    def get_image_annotation(self, image_id: int, target_labels: list) -&gt; tuple:\n        image_object = self.get_image_object(image_id)\n        name = image_object.getName()\n        annotations = self._get_image_annotations(image_object, target_labels)\n        return name, annotations\n\n    def _get_image_annotations(self, image_object: omero.gateway.ImageWrapper, annotation_keys: list) -&gt; dict:\n        annotations = {}\n        for omero_annotation in image_object.listAnnotations():\n            if omero_annotation.OMERO_TYPE == omero.model.MapAnnotationI:\n                for annotation_key in annotation_keys:\n                    for annotation in omero_annotation.getMapValue():\n                        if annotation.name.lower() == annotation_key.lower():\n                            annotations[annotation_key] = annotation.value\n        return annotations\n\n    def print_projects(self):\n        projects = self.conn.listProjects()      # may include other users' data\n        for project in projects:\n            print_omero_object(project)\n</code></pre>"},{"location":"references/#OmeSliCC.OmeroLabelReader","title":"<code>OmeroLabelReader</code>","text":""},{"location":"references/#OmeSliCC.OmeroLabelReader.OmeroLabelReader","title":"<code>OmeroLabelReader</code>","text":"<p>Omero metadata extraction to label file</p> Source code in <code>OmeSliCC\\OmeroLabelReader.py</code> <pre><code>class OmeroLabelReader:\n    \"\"\"Omero metadata extraction to label file\"\"\"\n\n    params: dict\n    \"\"\"input parameters\"\"\"\n    omero: Omero\n    \"\"\"Omero instance\"\"\"\n    manage_omero: bool\n    \"\"\"If responsible for managing Omero instance\"\"\"\n\n    def __init__(self, params: dict, omero: Omero = None):\n        self.params = params\n        self.manage_omero = (omero is None)\n        if self.manage_omero:\n            self.omero = Omero(params)\n        else:\n            self.omero = omero\n\n    def __enter__(self) -&gt; OmeroLabelReader:\n        if self.manage_omero:\n            self.omero.init()\n        return self\n\n    def __exit__(self, exc_type: type[BaseException], exc_value: BaseException, traceback: TracebackType):\n        if self.manage_omero:\n            self.omero.close()\n\n    def create_label_csv(self, image_ids):\n        image_names = []\n        image_annotations = []\n        input_params = self.params['input']\n        output_params = self.params['output']\n        input_labels = input_params.get('omero', {}).get('labels', [])\n        logging.info(f'Matching images: {len(image_ids)}')\n        for image_id in image_ids:\n            name, annotations = self.omero.get_image_annotation(image_id, input_labels)\n            image_names.append(name)\n            image_annotations.append(annotations)\n        df = pd.DataFrame(index=image_ids, data=image_annotations)\n        df.index.name = 'omero_id'\n        for input_label in input_labels:\n            if input_label in df:\n                logging.info(f'Label {input_label}:\\n' + df[input_label].value_counts().to_string())\n        df.insert(0, 'omero_name', image_names)\n        df['path'] = [image_name + '.' + output_params['format'] for image_name in image_names]\n        log_path = os.path.dirname(output_params['csv'])\n        if not os.path.exists(log_path):\n            os.makedirs(log_path)\n        df.to_csv(output_params['csv'])\n</code></pre>"},{"location":"references/#OmeSliCC.OmeroLabelReader.OmeroLabelReader.manage_omero","title":"<code>manage_omero = omero is None</code>  <code>instance-attribute</code>","text":"<p>If responsible for managing Omero instance</p>"},{"location":"references/#OmeSliCC.OmeroLabelReader.OmeroLabelReader.omero","title":"<code>omero</code>  <code>instance-attribute</code>","text":"<p>Omero instance</p>"},{"location":"references/#OmeSliCC.OmeroLabelReader.OmeroLabelReader.params","title":"<code>params = params</code>  <code>instance-attribute</code>","text":"<p>input parameters</p>"},{"location":"references/#OmeSliCC.OmeroSource","title":"<code>OmeroSource</code>","text":""},{"location":"references/#OmeSliCC.OmeroSource.OmeroSource","title":"<code>OmeroSource</code>","text":"<p>               Bases: <code>OmeSource</code></p> <p>Omero image source</p> Source code in <code>OmeSliCC\\OmeroSource.py</code> <pre><code>class OmeroSource(OmeSource):\n    \"\"\"Omero image source\"\"\"\n\n    omero: Omero\n    \"\"\"Omero instance\"\"\"\n    image_id: int\n    \"\"\"Omero image id\"\"\"\n    image_object: omero.gateway.ImageWrapper\n    \"\"\"Omero image object\"\"\"\n    pixels_store: omero.gateway.ProxyObjectWrapper\n    \"\"\"Raw pixels store object\"\"\"\n    pixels_store_pyramid_order: list\n    \"\"\"Raw pixels store pyramid sizes order (pixel store level order not guaranteed) \"\"\"\n\n    def __init__(self,\n                 omero: Omero,\n                 image_id: int,\n                 source_pixel_size: list = None,\n                 target_pixel_size: list = None,\n                 source_info_required: bool = False):\n\n        super().__init__()\n        self.omero = omero\n        self.image_id = image_id\n        image_object = self.omero.get_image_object(image_id)\n        self.image_object = image_object\n\n        zsize = get_default(image_object.getSizeZ(), 1)\n        nchannels = np.sum([channel.getLogicalChannel().getSamplesPerPixel() for channel in image_object.getChannels()])\n        pixel_type = np.dtype(image_object.getPixelsType())\n\n        self.pixels_store = self.omero.create_pixels_store(image_object)\n        for resolution in self.pixels_store.getResolutionDescriptions():\n            self.sizes.append((resolution.sizeX, resolution.sizeY))\n            self.sizes_xyzct.append((resolution.sizeX, resolution.sizeY, zsize, nchannels, 1))\n            self.pixel_types.append(pixel_type)\n            self.pixel_nbits.append(pixel_type.itemsize * 8)\n\n        if not self.sizes:\n            xsize, ysize = image_object.getSizeX(), image_object.getSizeY()\n            self.sizes.append((xsize, ysize))\n            self.sizes_xyzct.append((xsize, ysize, zsize, nchannels, 1))\n            self.pixel_types.append(pixel_type)\n            self.pixel_nbits.append(pixel_type.itemsize * 8)\n\n        # Omero API issue: pixel store level order not guaranteed\n        default_level = self.pixels_store.getResolutionLevel()\n        nlevels = self.pixels_store.getResolutionLevels()\n        if default_level != 0:\n            # reverse order\n            self.pixels_store_pyramid_order = list(reversed(range(nlevels)))\n        else:\n            # default order\n            self.pixels_store_pyramid_order = list(range(nlevels))\n\n        self.is_rgb = nchannels in (3, 4)\n\n        self._init_metadata(image_object.getName(),\n                            source_pixel_size=source_pixel_size,\n                            target_pixel_size=target_pixel_size,\n                            source_info_required=source_info_required)\n\n        # currently only support/output yxc\n        self.dimension_order = 'yxc'\n\n    def _find_metadata(self):\n        image_object = self.image_object\n        self.source_pixel_size = [(get_default(image_object.getPixelSizeX(), 0), self.default_physical_unit),\n                                  (get_default(image_object.getPixelSizeY(), 0), self.default_physical_unit),\n                                  (get_default(image_object.getPixelSizeZ(), 0), self.default_physical_unit)]\n        objective_settings = image_object.getObjectiveSettings()\n        if objective_settings:\n            self.source_mag = objective_settings.getObjective().getNominalMagnification()\n        else:\n            self.source_mag = 0\n        self.channels = []\n        for channeli, channel0 in enumerate(image_object.getChannels()):\n            channel = {'label': get_default(channel0.getName(), str(channeli)),\n                       'color': int_to_rgba(channel0.getColor().getInt())}\n            self.channels.append(channel)\n\n    def create_xml_metadata(self, output_filename: str, combine_rgb: bool = True, pyramid_sizes_add: list = None) -&gt; str:\n        return create_ome_metadata_from_omero(self, self.image_object, output_filename, combine_rgb=combine_rgb,\n                                              pyramid_sizes_add=pyramid_sizes_add)\n\n    def get_thumbnail(self, target_size: tuple, precise: bool = False) -&gt; np.ndarray:\n        image_bytes = self.image_object.getThumbnail(target_size)\n        image_stream = io.BytesIO(image_bytes)\n        image = np.array(PIL.Image.open(image_stream))\n        return image\n\n    def _asarray_level(self, level: int, **slicing) -&gt; np.ndarray:\n        x0, x1 = slicing.get('x0', 0), slicing.get('x1', -1)\n        y0, y1 = slicing.get('y0', 0), slicing.get('y1', -1)\n        c, t, z = slicing.get('c'), slicing.get('t'), slicing.get('z')\n        if x1 &lt; 0 or y1 &lt; 0:\n            x1, y1 = self.sizes[level]\n        if t is None:\n            t = 0\n        if z is None:\n            z = 0\n\n        w, h = x1 - x0, y1 - y0\n        if c is not None:\n            channels = [c]\n        else:\n            channels = range(self.get_nchannels())\n        shape = h, w, len(channels)\n        image = np.zeros(shape, dtype=self.pixel_types[level])\n        pixels_store = self.pixels_store\n        pixels_store_level = self.pixels_store_pyramid_order[level]\n        if pixels_store.getResolutionLevel() != pixels_store_level:\n            pixels_store.setResolutionLevel(pixels_store_level)\n        for c in channels:\n            tile0 = pixels_store.getTile(z, c, t, x0, y0, w, h)\n            tile = np.frombuffer(tile0, dtype=image.dtype).reshape(h, w)\n            image[..., c] = tile\n\n        out = redimension_data(image, self.dimension_order, self.get_dimension_order())\n        return out\n\n    def close(self):\n        self.pixels_store.close()\n</code></pre>"},{"location":"references/#OmeSliCC.OmeroSource.OmeroSource.image_id","title":"<code>image_id = image_id</code>  <code>instance-attribute</code>","text":"<p>Omero image id</p>"},{"location":"references/#OmeSliCC.OmeroSource.OmeroSource.image_object","title":"<code>image_object = image_object</code>  <code>instance-attribute</code>","text":"<p>Omero image object</p>"},{"location":"references/#OmeSliCC.OmeroSource.OmeroSource.omero","title":"<code>omero = omero</code>  <code>instance-attribute</code>","text":"<p>Omero instance</p>"},{"location":"references/#OmeSliCC.OmeroSource.OmeroSource.pixels_store","title":"<code>pixels_store = self.omero.create_pixels_store(image_object)</code>  <code>instance-attribute</code>","text":"<p>Raw pixels store object</p>"},{"location":"references/#OmeSliCC.OmeroSource.OmeroSource.pixels_store_pyramid_order","title":"<code>pixels_store_pyramid_order</code>  <code>instance-attribute</code>","text":"<p>Raw pixels store pyramid sizes order (pixel store level order not guaranteed)</p>"},{"location":"references/#OmeSliCC.PlainImageSource","title":"<code>PlainImageSource</code>","text":""},{"location":"references/#OmeSliCC.PlainImageSource.PlainImageSource","title":"<code>PlainImageSource</code>","text":"<p>               Bases: <code>OmeSource</code></p> <p>Plain common format image source</p> Source code in <code>OmeSliCC\\PlainImageSource.py</code> <pre><code>class PlainImageSource(OmeSource):\n    \"\"\"Plain common format image source\"\"\"\n\n    filename: str\n    \"\"\"original filename\"\"\"\n    loaded: bool\n    \"\"\"if image data is loaded\"\"\"\n    arrays: list\n    \"\"\"list of all image arrays for different sizes\"\"\"\n\n    def __init__(self,\n                 filename: str,\n                 source_pixel_size: list = None,\n                 target_pixel_size: list = None,\n                 source_info_required: bool = False):\n\n        super().__init__()\n        self.loaded = False\n        self.arrays = []\n\n        self.image = Image.open(filename)\n        self.metadata = get_pil_metadata(self.image)\n        size = (self.image.width, self.image.height)\n        self.sizes = [size]\n        nchannels = len(self.image.getbands())\n        size_xyzct = (self.image.width, self.image.height, self.image.n_frames, nchannels, 1)\n        self.sizes_xyzct = [size_xyzct]\n        pixelinfo = pilmode_to_pixelinfo(self.image.mode)\n        self.pixel_types = [pixelinfo[0]]\n        self.pixel_nbits = [pixelinfo[1]]\n\n        dimension_order = 'yx'\n        if self.image.n_frames &gt; 1:\n            dimension_order = 'z' + dimension_order\n        if nchannels &gt; 1:\n            dimension_order += 'c'\n        self.dimension_order = dimension_order\n\n        self.is_rgb = nchannels in (3, 4)\n\n        self._init_metadata(filename,\n                            source_pixel_size=source_pixel_size,\n                            target_pixel_size=target_pixel_size,\n                            source_info_required=source_info_required)\n\n    def _find_metadata(self):\n        self.source_pixel_size = []\n        pixel_size_unit = None\n        pixel_size_z = None\n\n        description = self.metadata.get('ImageDescription', '')\n        if description != '':\n            metadata = desc_to_dict(description)\n            if 'spacing' in metadata:\n                pixel_size_unit = metadata.get('unit', '')\n                if not isinstance(pixel_size_unit, str):\n                    pixel_size_unit = 'micrometer'\n                pixel_size_z = metadata['spacing']\n        if not pixel_size_unit:\n            pixel_size_unit = self.metadata.get('ResolutionUnit')\n            if pixel_size_unit is not None:\n                pixel_size_unit = str(RESUNIT(pixel_size_unit).name).lower()\n                if pixel_size_unit == 'none':\n                    pixel_size_unit = ''\n        res0 = self.metadata.get('XResolution')\n        if res0 is not None:\n            self.source_pixel_size.append((1 / float(res0), pixel_size_unit))\n        res0 = self.metadata.get('YResolution')\n        if res0 is not None:\n            self.source_pixel_size.append((1 / float(res0), pixel_size_unit))\n        if pixel_size_z is not None:\n            self.source_pixel_size.append((pixel_size_z, pixel_size_unit))\n        self.source_mag = self.metadata.get('Mag', 0)\n        self.channels = [{'label': ''}]\n\n    def load(self):\n        self.unload()\n        for level in range(len(self.sizes)):\n            self.arrays.append(self._asarray_level(level))\n        self.loaded = True\n\n    def unload(self):\n        for array in self.arrays:\n            del array\n        self.arrays = []\n        self.loaded = False\n\n    def _asarray_level(self, level: int, **slicing) -&gt; np.ndarray:\n        nframes = self.image.n_frames\n        if self.loaded:\n            image = self.arrays[level]\n        elif nframes &gt; 1:\n            shape = [nframes] + list(np.array(self.image).shape)\n            image = np.zeros(shape, dtype=self.pixel_types[level])\n            for framei in range(nframes):\n                self.image.seek(framei)\n                image[framei] = np.array(self.image)\n        else:\n            image = np.array(self.image)\n\n        redim = redimension_data(image, self.dimension_order, self.get_dimension_order())\n        slicing = get_numpy_slicing(self.get_dimension_order(), **slicing)\n        out = redim[slicing]\n        return out\n</code></pre>"},{"location":"references/#OmeSliCC.PlainImageSource.PlainImageSource.arrays","title":"<code>arrays = []</code>  <code>instance-attribute</code>","text":"<p>list of all image arrays for different sizes</p>"},{"location":"references/#OmeSliCC.PlainImageSource.PlainImageSource.filename","title":"<code>filename</code>  <code>instance-attribute</code>","text":"<p>original filename</p>"},{"location":"references/#OmeSliCC.PlainImageSource.PlainImageSource.loaded","title":"<code>loaded = False</code>  <code>instance-attribute</code>","text":"<p>if image data is loaded</p>"},{"location":"references/#OmeSliCC.TiffSource","title":"<code>TiffSource</code>","text":""},{"location":"references/#OmeSliCC.TiffSource.TiffSource","title":"<code>TiffSource</code>","text":"<p>               Bases: <code>OmeSource</code></p> <p>Tiff-compatible image source</p> Source code in <code>OmeSliCC\\TiffSource.py</code> <pre><code>class TiffSource(OmeSource):\n    \"\"\"Tiff-compatible image source\"\"\"\n\n    filename: str\n    \"\"\"original filename\"\"\"\n    compressed: bool\n    \"\"\"if image data is loaded compressed\"\"\"\n    decompressed: bool\n    \"\"\"if image data is loaded decompressed\"\"\"\n    pages: list\n    \"\"\"list of all relevant TiffPages\"\"\"\n    data: bytes\n    \"\"\"raw un-decoded image byte data\"\"\"\n    arrays: list\n    \"\"\"list of all image arrays for different sizes\"\"\"\n\n    def __init__(self,\n                 filename: str,\n                 source_pixel_size: list = None,\n                 target_pixel_size: list = None,\n                 source_info_required: bool = False,\n                 executor: ThreadPoolExecutor = None):\n\n        super().__init__()\n        self.compressed = False\n        self.decompressed = False\n        self.executor = executor\n        self.data = bytes()\n        self.arrays = []\n        photometric = None\n        nchannels = 1\n\n        tiff = TiffFile(filename)\n        self.tiff = tiff\n        self.first_page = tiff.pages.first\n        if tiff.is_ome and tiff.ome_metadata is not None:\n            xml_metadata = tiff.ome_metadata\n            self.metadata = XmlDict.xml2dict(xml_metadata)\n            if 'OME' in self.metadata:\n                self.metadata = self.metadata['OME']\n                self.has_ome_metadata = True\n            if 'BinaryOnly' in self.metadata:\n                # binary image only; get metadata from metadata file instead\n                self.has_ome_metadata = False\n                metdata_filename = os.path.join(os.path.dirname(filename),\n                                                self.metadata['BinaryOnly'].get('MetadataFile'))\n                if os.path.isfile(metdata_filename):\n                    metdata_tiff = TiffFile(metdata_filename)\n                    if metdata_tiff.is_ome and metdata_tiff.ome_metadata is not None:\n                        xml_metadata = metdata_tiff.ome_metadata\n                        self.metadata = XmlDict.xml2dict(xml_metadata)\n                        if 'OME' in self.metadata:\n                            self.metadata = self.metadata['OME']\n                            images = self.metadata.get('Image')\n                            if isinstance(images, list):\n                                for image in images:\n                                    if image.get('Name', '').lower() == get_filetitle(filename).lower():\n                                        self.metadata['Image'] = image\n                                        break\n                            self.has_ome_metadata = True\n\n        if self.has_ome_metadata:\n            pass\n        elif tiff.is_imagej:\n            self.metadata = tiff.imagej_metadata\n        elif self.first_page.description:\n            self.metadata = desc_to_dict(self.first_page.description)\n        self.tags = tags_to_dict(self.first_page.tags)\n        if 'FEI_TITAN' in self.tags:\n            metadata = tifffile.xml2dict(self.tags.pop('FEI_TITAN'))\n            if 'FeiImage' in metadata:\n                metadata = metadata['FeiImage']\n            self.metadata.update(metadata)\n\n        if tiff.series:\n            series0 = tiff.series[0]\n            self.dimension_order = series0.axes\n            photometric = series0.keyframe.photometric\n        self.pages = get_tiff_pages(tiff)\n        for page0 in self.pages:\n            if isinstance(page0, list):\n                page = page0[0]\n                npages = len(page0)\n            else:\n                page = page0\n                npages = 1\n            self.npages = npages\n            if not self.dimension_order:\n                self.dimension_order = page.axes\n                photometric = page.photometric\n            shape = page.shape\n            nchannels = shape[2] if len(shape) &gt; 2 else 1\n            nt = 1\n            if isinstance(page, TiffPage):\n                width = page.imagewidth\n                height = page.imagelength\n                self.depth = page.imagedepth\n                depth = self.depth * npages\n                bitspersample = page.bitspersample\n            else:\n                width = shape[1]\n                height = shape[0]\n                depth = npages\n                if len(shape) &gt; 2:\n                    self.depth = shape[2]\n                    depth *= self.depth\n                bitspersample = page.dtype.itemsize * 8\n            if self.has_ome_metadata:\n                pixels = ensure_list(self.metadata.get('Image', {}))[0].get('Pixels', {})\n                depth = int(pixels.get('SizeZ', depth))\n                nchannels = int(pixels.get('SizeC', nchannels))\n                nt = int(pixels.get('SizeT', nt))\n            self.sizes.append((width, height))\n            self.sizes_xyzct.append((width, height, depth, nchannels, nt))\n            self.pixel_types.append(page.dtype)\n            self.pixel_nbits.append(bitspersample)\n\n        self.fh = tiff.filehandle\n        self.dimension_order = self.dimension_order.lower().replace('s', 'c').replace('r', '')\n\n        self.is_rgb = (photometric in (PHOTOMETRIC.RGB, PHOTOMETRIC.PALETTE) and nchannels in (3, 4))\n\n        self._init_metadata(filename,\n                            source_pixel_size=source_pixel_size,\n                            target_pixel_size=target_pixel_size,\n                            source_info_required=source_info_required)\n\n    def _find_metadata(self):\n        pixel_size = []\n        # from OME metadata\n        if self.has_ome_metadata:\n            self._get_ome_metadata()\n            return\n\n        # from imageJ metadata\n        pixel_size_z = None\n        pixel_size_unit = self.metadata.get('unit', '').encode().decode('unicode_escape')\n        if pixel_size_unit == 'micron':\n            pixel_size_unit = self.default_physical_unit\n        if 'scales' in self.metadata:\n            for scale in self.metadata['scales'].split(','):\n                scale = scale.strip()\n                if scale != '':\n                    pixel_size.append((float(scale), pixel_size_unit))\n        if len(pixel_size) == 0 and self.metadata is not None and 'spacing' in self.metadata:\n            pixel_size_z = (self.metadata['spacing'], pixel_size_unit)\n        # from description\n        if len(pixel_size) &lt; 2 and 'pixelWidth' in self.metadata:\n            pixel_info = self.metadata['pixelWidth']\n            pixel_size.append((pixel_info['value'], pixel_info['unit']))\n            pixel_info = self.metadata['pixelHeight']\n            pixel_size.append((pixel_info['value'], pixel_info['unit']))\n        if len(pixel_size) &lt; 2 and 'MPP' in self.metadata:\n            pixel_size.append((self.metadata['MPP'], self.default_physical_unit))\n            pixel_size.append((self.metadata['MPP'], self.default_physical_unit))\n        # from page TAGS\n        if len(pixel_size) &lt; 2:\n            pixel_size_unit = self.tags.get('ResolutionUnit', '')\n            if isinstance(pixel_size_unit, Enum):\n                pixel_size_unit = pixel_size_unit.name\n            pixel_size_unit = pixel_size_unit.lower()\n            if pixel_size_unit == 'none':\n                pixel_size_unit = ''\n            res0 = convert_rational_value(self.tags.get('XResolution'))\n            if res0 is not None and res0 != 0:\n                pixel_size.append((1 / res0, pixel_size_unit))\n            res0 = convert_rational_value(self.tags.get('YResolution'))\n            if res0 is not None and res0 != 0:\n                pixel_size.append((1 / res0, pixel_size_unit))\n\n        position = []\n        xpos = convert_rational_value(self.tags.get('XPosition'))\n        ypos = convert_rational_value(self.tags.get('YPosition'))\n        if xpos is not None and ypos is not None:\n            position = [(xpos, pixel_size_unit), (ypos, pixel_size_unit)]\n\n        if pixel_size_z is not None and len(pixel_size) == 2:\n            pixel_size.append(pixel_size_z)\n\n        mag = self.metadata.get('Mag', self.metadata.get('AppMag', 0))\n\n        nchannels = self.get_nchannels()\n        photometric = str(self.metadata.get('PhotometricInterpretation', '')).lower().split('.')[-1]\n        if nchannels == 3:\n            channels = [{'label': photometric}]\n        else:\n            channels = [{'label': photometric}] * nchannels\n\n        self.source_pixel_size = pixel_size\n        self.source_mag = mag\n        self.channels = channels\n        self.position = position\n\n    def get_source_dask(self):\n        return self._load_as_dask()\n\n    def _load_as_dask(self):\n        if len(self.arrays) == 0:\n            for level in range(len(self.sizes)):\n                if self.tiff.is_mmstack:\n                    page = self.pages[level]\n                    if isinstance(page, list):\n                        page = page[0]\n                    data = da.from_zarr(page.aszarr())\n                else:\n                    data = da.from_zarr(self.tiff.aszarr(level=level))\n                if data.chunksize == data.shape:\n                    data = data.rechunk()\n                self.arrays.append(data)\n        return self.arrays\n\n    def _load_as_zarr(self):\n        if len(self.arrays) == 0:\n            import zarr\n            store = self.tiff.aszarr(multiscales=True)\n            group = zarr.group(store=store)\n            self.arrays = [arr for _, arr in group.arrays()]  # read-only zarr arrays\n        return self.arrays\n\n    def load(self, decompress: bool = False):\n        if decompress:\n            self.decompress()\n            self.decompressed = True\n        else:\n            self.fh.seek(0)\n            self.data = self.fh.read()\n            self.compressed = True\n\n    def unload(self):\n        del self.data\n        self.clear_arrays()\n        self.compressed = False\n        self.decompressed = False\n\n    def decompress(self):\n        self.clear_arrays()\n        for page in self.pages:\n            if isinstance(page, list):\n                array = []\n                for page1 in page:\n                    data = page1.asarray()\n                    if len(page) &gt; 1:\n                        array.append(data)\n                    else:\n                        array = data\n                array = np.asarray(array)\n            else:\n                array = page.asarray()\n            self.arrays.append(array)\n\n    def clear_arrays(self):\n        for array in self.arrays:\n            del array\n        self.arrays = []\n\n    def _asarray_level(self, level: int, **slicing) -&gt; np.ndarray:\n        if self.compressed and not self.decompressed:\n            out = self._decompress(level, **slicing)\n        else:\n            self._load_as_dask()\n            redim = redimension_data(self.arrays[level], self.dimension_order, self.get_dimension_order())\n            slices = get_numpy_slicing(self.get_dimension_order(), **slicing)\n            out = redim[slices]\n        return out\n\n    def _decompress(self, level: int, **slicing) -&gt; np.ndarray:\n        # based on tiffile asarray\n\n        if self.executor is None:\n            max_workers = (os.cpu_count() or 1) + 4\n            self.executor = ThreadPoolExecutor(max_workers)\n\n        x0, x1 = slicing.get('x0', 0), slicing.get('x1', -1)\n        y0, y1 = slicing.get('y0', 0), slicing.get('y1', -1)\n        c, t, z = slicing.get('c'), slicing.get('t'), slicing.get('z')\n        if x1 &lt; 0 or y1 &lt; 0:\n            x1, y1 = self.sizes[level]\n\n        dw = x1 - x0\n        dh = y1 - y0\n        xyzct = list(self.sizes_xyzct[level]).copy()\n        nz = xyzct[2]\n        nc = xyzct[3]\n\n        pages = self.pages[level]\n        if nz == self.npages and z is not None:\n            pages = [pages[z]]\n        elif t is not None:\n            pages = [pages[t]]\n        page = pages[0] if isinstance(pages, list) else pages\n        tile_height, tile_width = page.chunks[:2]\n        tile_y0, tile_x0 = y0 // tile_height, x0 // tile_width\n        tile_y1, tile_x1 = np.ceil([y1 / tile_height, x1 / tile_width]).astype(int)\n        w = (tile_x1 - tile_x0) * tile_width\n        h = (tile_y1 - tile_y0) * tile_height\n        niter_channels = nc if page.dims[0] == 'sample' else 1\n        tile_per_line = int(np.ceil(page.imagewidth / tile_width))\n        tile_per_channel = tile_per_line * int(np.ceil(page.imagelength / tile_height))\n        xyzct[0] = w\n        xyzct[1] = h\n\n        # Match internal Tiff page dimensions [separate sample, depth, length, width, contig sample]\n        n = self.npages\n        d = self.depth\n        s = nc\n        if self.npages == s &gt; 1:\n            # in case channels represented as pages\n            s = 1\n        shape = n, d, h, w, s\n        out = np.zeros(shape, page.dtype)\n\n        dataoffsets = []\n        databytecounts = []\n        tile_locations = []\n        for pagei, page in enumerate(pages):\n            for channeli in range(niter_channels):\n                for y in range(tile_y0, tile_y1):\n                    for x in range(tile_x0, tile_x1):\n                        index = channeli * tile_per_channel + y * tile_per_line + x\n                        if index &lt; len(page.databytecounts):\n                            offset = page.dataoffsets[index]\n                            count = page.databytecounts[index]\n                            if count &gt; 0:\n                                dataoffsets.append(offset)\n                                databytecounts.append(count)\n                                target_y = (y - tile_y0) * tile_height\n                                target_x = (x - tile_x0) * tile_width\n                                tile_locations.append((pagei, 0, target_y, target_x, channeli))\n\n            self._decode(page, dataoffsets, databytecounts, tile_locations, out)\n\n        target_y0 = y0 - tile_y0 * tile_height\n        target_x0 = x0 - tile_x0 * tile_width\n        image = out[:, :, target_y0: target_y0 + dh, target_x0: target_x0 + dw, :]\n        # 'ndyxs' -&gt; 'tzyxc'\n        if image.shape[0] == nc &gt; 1:\n            image = np.swapaxes(image, 0, -1)\n        elif image.shape[0] == nz &gt; 1:\n            image = np.swapaxes(image, 0, 1)\n        # 'tzyxc' -&gt; 'tczyx'\n        image = np.moveaxis(image, -1, 1)\n        return image\n\n    def _decode(self, page: TiffPage, dataoffsets: list, databytecounts: list, tile_locations: list, out: np.ndarray):\n        def process_decoded(decoded, index, out=out):\n            segment, indices, shape = decoded\n            s = tile_locations[index]\n            e = np.array(s) + ([1] + list(shape))\n            # Note: numpy is not thread-safe\n            out[s[0]: e[0],\n                s[1]: e[1],\n                s[2]: e[2],\n                s[3]: e[3],\n                s[4]: e[4]] = segment\n\n        for _ in self._segments(\n                process_function=process_decoded,\n                page=page,\n                dataoffsets=dataoffsets,\n                databytecounts=databytecounts\n        ):\n            pass\n\n    def _segments(self, process_function: callable, page: TiffPage, dataoffsets: list, databytecounts: list) -&gt; tuple:\n        # based on tiffile segments\n        def decode(args, page=page, process_function=process_function):\n            decoded = page.decode(*args, jpegtables=page.jpegtables)\n            return process_function(decoded, args[1])\n\n        tile_segments = []\n        for index in range(len(dataoffsets)):\n            offset = dataoffsets[index]\n            bytecount = databytecounts[index]\n            if self.compressed:\n                segment = self.data[offset:offset + bytecount]\n            else:\n                fh = page.parent.filehandle\n                fh.seek(offset)\n                segment = fh.read(bytecount)\n            tile_segment = (segment, index)\n            tile_segments.append(tile_segment)\n            # yield decode(tile_segment)\n        yield from self.executor.map(decode, tile_segments, timeout=10)\n\n    def close(self):\n        self.tiff.close()\n        self.fh.close()\n</code></pre>"},{"location":"references/#OmeSliCC.TiffSource.TiffSource.arrays","title":"<code>arrays = []</code>  <code>instance-attribute</code>","text":"<p>list of all image arrays for different sizes</p>"},{"location":"references/#OmeSliCC.TiffSource.TiffSource.compressed","title":"<code>compressed = False</code>  <code>instance-attribute</code>","text":"<p>if image data is loaded compressed</p>"},{"location":"references/#OmeSliCC.TiffSource.TiffSource.data","title":"<code>data = bytes()</code>  <code>instance-attribute</code>","text":"<p>raw un-decoded image byte data</p>"},{"location":"references/#OmeSliCC.TiffSource.TiffSource.decompressed","title":"<code>decompressed = False</code>  <code>instance-attribute</code>","text":"<p>if image data is loaded decompressed</p>"},{"location":"references/#OmeSliCC.TiffSource.TiffSource.filename","title":"<code>filename</code>  <code>instance-attribute</code>","text":"<p>original filename</p>"},{"location":"references/#OmeSliCC.TiffSource.TiffSource.pages","title":"<code>pages = get_tiff_pages(tiff)</code>  <code>instance-attribute</code>","text":"<p>list of all relevant TiffPages</p>"},{"location":"references/#OmeSliCC.XmlDict","title":"<code>XmlDict</code>","text":""},{"location":"references/#OmeSliCC.XmlDict.XmlDict","title":"<code>XmlDict</code>","text":"<p>               Bases: <code>dict</code></p> <p>xmltodict type dictionary providing and propagating access to keys without @ sign</p> Source code in <code>OmeSliCC\\XmlDict.py</code> <pre><code>class XmlDict(dict):\n    \"\"\"xmltodict type dictionary providing and propagating access to keys without @ sign\"\"\"\n\n    def __getitem__(self, key: str):\n        at_key = '@' + key\n        if key not in self and at_key in self:\n            key = at_key\n        value = dict.__getitem__(self, key)\n        if isinstance(value, dict):\n            value = XmlDict(value)\n        if isinstance(value, list):\n            value = XmlList(value)\n        return value\n\n    def get(self, key: str, default=None):\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def copy(self) -&gt; XmlDict:\n        return XmlDict(dict.copy(self))\n</code></pre>"},{"location":"references/#OmeSliCC.XmlDict.XmlList","title":"<code>XmlList</code>","text":"<p>               Bases: <code>list</code></p> <p>xmltodict type list propagating access to keys without @ sign</p> Source code in <code>OmeSliCC\\XmlDict.py</code> <pre><code>class XmlList(list):\n    \"\"\"xmltodict type list propagating access to keys without @ sign\"\"\"\n\n    def __getitem__(self, index: int):\n        value = list.__getitem__(self, index)\n        if isinstance(value, dict):\n            value = XmlDict(value)\n        if isinstance(value, list):\n            value = XmlList(value)\n        return value\n\n    def __iter__(self) -&gt; XmlList:\n        self.i = 0\n        return self\n\n    def __next__(self):\n        if self.i &lt; len(self):\n            item = self[self.i]\n            self.i += 1\n            return item\n        else:\n            raise StopIteration\n</code></pre>"},{"location":"references/#OmeSliCC.ZarrSource","title":"<code>ZarrSource</code>","text":""},{"location":"references/#OmeSliCC.ZarrSource.ZarrSource","title":"<code>ZarrSource</code>","text":"<p>               Bases: <code>OmeSource</code></p> <p>Zarr-compatible image source</p> Source code in <code>OmeSliCC\\ZarrSource.py</code> <pre><code>class ZarrSource(OmeSource):\n    \"\"\"Zarr-compatible image source\"\"\"\n\n    filename: str\n    \"\"\"original filename / URL\"\"\"\n    levels: list\n    \"\"\"list of all image arrays for different sizes\"\"\"\n\n    def __init__(self, filename: str,\n                 source_pixel_size: list = None,\n                 target_pixel_size: list = None,\n                 source_info_required: bool = False):\n\n        super().__init__()\n\n        try:\n            if filename.startswith((\"http\", \"s3\")):\n                cls = RemoteStore\n            else:\n                cls = LocalStore\n            store_path = cls(filename)\n            root = zarr.open_group(store=store_path)\n            self.metadata = root.attrs.asdict()\n\n            paths = []\n            dimension_order = 'tczyx'\n            if 'multiscales' in self.metadata:\n                for scale in self.metadata.get('multiscales', []):\n                    for index, dataset in enumerate(scale.get('datasets', [])):\n                        paths.append(dataset.get('path', str(index)))\n                    axes = scale.get('axes', [])\n                    if len(axes) &gt; 0:\n                        dimension_order = ''.join([axis.get('name') for axis in axes])\n            else:\n                paths = root.array_keys()\n            self.dimension_order = dimension_order\n\n            self.levels = []\n            for path in paths:\n                data = root.get(path)\n                self.levels.append(data)\n\n                xyzct = [1, 1, 1, 1, 1]\n                for i, n in enumerate(data.shape):\n                    xyzct_index = 'xyzct'.index(dimension_order[i])\n                    xyzct[xyzct_index] = n\n                self.sizes_xyzct.append(xyzct)\n                self.sizes.append((xyzct[0], xyzct[1]))\n                self.pixel_types.append(data.dtype)\n                self.pixel_nbits.append(data.dtype.itemsize * 8)\n        except Exception as e:\n            raise FileNotFoundError(f'Read error: {e}')\n\n        self._init_metadata(filename,\n                            source_pixel_size=source_pixel_size,\n                            target_pixel_size=target_pixel_size,\n                            source_info_required=source_info_required)\n\n    def _find_metadata(self):\n        pixel_size = []\n        channels = []\n        for scale in self.metadata.get('multiscales', []):\n            axes = ''.join([axis.get('name', '') for axis in scale.get('axes', [])])\n            units = [axis.get('unit', '') for axis in scale.get('axes', [])]\n            scale1 = [0, 0, 0, 0, 0]\n            datasets = scale.get('datasets')\n            if datasets is not None:\n                coordinateTransformations = datasets[0].get('coordinateTransformations')\n                if coordinateTransformations is not None:\n                    scale1 = coordinateTransformations[0].get('scale', scale1)\n            if 'z' in axes:\n                pixel_size = [\n                    (scale1[axes.index('x')], units[axes.index('x')]),\n                    (scale1[axes.index('y')], units[axes.index('y')]),\n                    (scale1[axes.index('z')], units[axes.index('z')])]\n            else:\n                pixel_size = [(0, ''), (0, ''), (0, '')]\n        nchannels = self.sizes_xyzct[0][3]\n        for data in self.metadata.values():\n            if isinstance(data, dict):\n                n = len(data.get('channels', []))\n                for channel0 in data.get('channels', []):\n                    channel = XmlDict({'@Name': channel0.get('label'), '@SamplesPerPixel': nchannels // n})\n                    if 'color' in channel0:\n                        channel['@Color'] = channel0['color']\n                    channels.append(channel)\n        if len(channels) == 0:\n            if nchannels == 3:\n                channels = [XmlDict({'@Name': '', '@SamplesPerPixel': nchannels})]\n            else:\n                channels = [XmlDict({'@Name': '', '@SamplesPerPixel': 1})] * nchannels\n        self.source_pixel_size = pixel_size\n        self.channels = channels\n        self.source_mag = 0\n\n    def _asarray_level(self, level: int, x0: float = 0, y0: float = 0, x1: float = -1, y1: float = -1) -&gt; np.ndarray:\n        size_xyzct = self.sizes_xyzct[level]\n        if x1 &lt; 0 or y1 &lt; 0:\n            x1, y1, _, _, _ = size_xyzct\n        if self.dimension_order.endswith('yx'):\n            image = self.levels[level][..., y0:y1, x0:x1].squeeze()\n            if len(image.shape) &gt; 2:\n                image = np.moveaxis(image, 0, -1)  # move axis 0 (channel/z) to end\n        else:\n            image = self.levels[level][y0:y1, x0:x1].squeeze()\n        return image\n</code></pre>"},{"location":"references/#OmeSliCC.ZarrSource.ZarrSource.filename","title":"<code>filename</code>  <code>instance-attribute</code>","text":"<p>original filename / URL</p>"},{"location":"references/#OmeSliCC.ZarrSource.ZarrSource.levels","title":"<code>levels = []</code>  <code>instance-attribute</code>","text":"<p>list of all image arrays for different sizes</p>"}]}